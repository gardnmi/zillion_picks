{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# Put this notebook in a utils.py \"funcion load model data set\"\n",
    "# Train Regression Model for Spread and Classification Model for Straight Pick Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import dask.dataframe as dd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    " \n",
    "# Notebook Options\n",
    "pd.options.display.max_columns = 20\n",
    "filepath= Path('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     game_id                 game_date  season  week season_type  \\\n",
       "0  400603840 2015-09-03 18:00:00+00:00    2015     1     regular   \n",
       "1  400763593 2015-09-03 18:00:00+00:00    2015     1     regular   \n",
       "2  400763399 2015-09-03 19:00:00+00:00    2015     1     regular   \n",
       "3  400756896 2015-09-03 19:00:00+00:00    2015     1     regular   \n",
       "4  400787299 2015-09-03 19:00:00+00:00    2015     1     regular   \n",
       "\n",
       "   neutral_site  conference_game  attendance  venue_id  home_id  \\\n",
       "0          True            False     51664.0      3628     2579   \n",
       "1         False            False     39184.0      3652     2116   \n",
       "2         False            False     19717.0      3786     2117   \n",
       "3         False            False     27126.0      3630      154   \n",
       "4         False            False     10473.0      3919     2050   \n",
       "\n",
       "          home_team    home_conference  away_id              away_team  \\\n",
       "0    South Carolina                SEC      153         North Carolina   \n",
       "1               UCF  American Athletic     2229  Florida International   \n",
       "2  Central Michigan       Mid-American      197         Oklahoma State   \n",
       "3       Wake Forest                ACC     2210                   Elon   \n",
       "4        Ball State       Mid-American     2678                    VMI   \n",
       "\n",
       "  away_conference   dome   elevation  grass  capacity_perc  \n",
       "0             ACC  False  220.877747   True       0.685090  \n",
       "1  Conference USA  False   20.941137  False       0.886396  \n",
       "2          Big 12  False  240.900772  False       0.599574  \n",
       "3             NaN  False  283.548584  False       0.861143  \n",
       "4             NaN  False  285.481781  False       0.465467  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_id</th>\n      <th>game_date</th>\n      <th>season</th>\n      <th>week</th>\n      <th>season_type</th>\n      <th>neutral_site</th>\n      <th>conference_game</th>\n      <th>attendance</th>\n      <th>venue_id</th>\n      <th>home_id</th>\n      <th>home_team</th>\n      <th>home_conference</th>\n      <th>away_id</th>\n      <th>away_team</th>\n      <th>away_conference</th>\n      <th>dome</th>\n      <th>elevation</th>\n      <th>grass</th>\n      <th>capacity_perc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>400603840</td>\n      <td>2015-09-03 18:00:00+00:00</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>regular</td>\n      <td>True</td>\n      <td>False</td>\n      <td>51664.0</td>\n      <td>3628</td>\n      <td>2579</td>\n      <td>South Carolina</td>\n      <td>SEC</td>\n      <td>153</td>\n      <td>North Carolina</td>\n      <td>ACC</td>\n      <td>False</td>\n      <td>220.877747</td>\n      <td>True</td>\n      <td>0.685090</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>400763593</td>\n      <td>2015-09-03 18:00:00+00:00</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>regular</td>\n      <td>False</td>\n      <td>False</td>\n      <td>39184.0</td>\n      <td>3652</td>\n      <td>2116</td>\n      <td>UCF</td>\n      <td>American Athletic</td>\n      <td>2229</td>\n      <td>Florida International</td>\n      <td>Conference USA</td>\n      <td>False</td>\n      <td>20.941137</td>\n      <td>False</td>\n      <td>0.886396</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>400763399</td>\n      <td>2015-09-03 19:00:00+00:00</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>regular</td>\n      <td>False</td>\n      <td>False</td>\n      <td>19717.0</td>\n      <td>3786</td>\n      <td>2117</td>\n      <td>Central Michigan</td>\n      <td>Mid-American</td>\n      <td>197</td>\n      <td>Oklahoma State</td>\n      <td>Big 12</td>\n      <td>False</td>\n      <td>240.900772</td>\n      <td>False</td>\n      <td>0.599574</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>400756896</td>\n      <td>2015-09-03 19:00:00+00:00</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>regular</td>\n      <td>False</td>\n      <td>False</td>\n      <td>27126.0</td>\n      <td>3630</td>\n      <td>154</td>\n      <td>Wake Forest</td>\n      <td>ACC</td>\n      <td>2210</td>\n      <td>Elon</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>283.548584</td>\n      <td>False</td>\n      <td>0.861143</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>400787299</td>\n      <td>2015-09-03 19:00:00+00:00</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>regular</td>\n      <td>False</td>\n      <td>False</td>\n      <td>10473.0</td>\n      <td>3919</td>\n      <td>2050</td>\n      <td>Ball State</td>\n      <td>Mid-American</td>\n      <td>2678</td>\n      <td>VMI</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>285.481781</td>\n      <td>False</td>\n      <td>0.465467</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Games\n",
    "usecols = ['id', 'season', 'week', 'season_type', 'start_date', 'neutral_site', 'conference_game', 'attendance', 'venue_id',\n",
    " 'home_id', 'home_team', 'home_conference', 'home_points', 'home_line_scores', 'away_id', 'away_team', 'away_conference', 'away_points', 'away_line_scores',]\n",
    "\n",
    "dfs = []\n",
    "for file in filepath.rglob('games.csv'):\n",
    "\n",
    "    df = pd.read_csv(file, usecols=usecols, parse_dates=['start_date'])\n",
    "    dfs.append(df)\n",
    "\n",
    "games_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "games_df['actual_rolling_spread'] =  games_df.away_points - games_df.home_points\n",
    "games_df['actual_rolling_overunder'] = games_df.home_points + games_df.away_points \n",
    "games_df = games_df.rename(columns=dict(id='game_id'))\n",
    "games_df = games_df.rename(columns=dict(start_date='game_date'))\n",
    "\n",
    "# Venues \n",
    "usecols = ['id', 'name', 'capacity', 'grass', 'city', 'state', 'elevation', 'year_constructed', 'dome', 'timezone']\n",
    "\n",
    "venues_df = pd.read_csv(filepath/'venues.csv', usecols=usecols)\n",
    "venues_df = venues_df.rename(columns=dict(id='venue_id'))\n",
    "\n",
    "# Convert to Bool Columns\n",
    "venues_df['grass'] = venues_df['grass'].astype('bool')\n",
    "venues_df['dome'] = venues_df['dome'].astype('bool')\n",
    "\n",
    "games_df = games_df.merge(venues_df[['venue_id', 'capacity', 'dome', 'elevation', 'grass']], how='left', on='venue_id', validate='many_to_one')\n",
    "# calculate capacity %\n",
    "games_df['capacity_perc'] = games_df['attendance'] / games_df['capacity'] \n",
    "games_df = games_df.drop('capacity', axis=1)\n",
    "\n",
    "# Split out Quarter Scores\n",
    "games_df.home_line_scores = games_df.home_line_scores.astype(str).str.replace('[', '').str.replace(']', '').str.replace('nan', '0,0,0,0')\n",
    "games_df.away_line_scores = games_df.away_line_scores.astype(str).str.replace('[', '').str.replace(']', '').str.replace('nan', '0,0,0,0')\n",
    "\n",
    "columns = ['first_qtr_score', 'second_qtr_score', 'third_qtr_score', 'fourth_qtr_score']\n",
    "\n",
    "games_df[[f'home_{col}' for col in columns]] = games_df.home_line_scores.str.split(',', expand=True).iloc[:, :4].replace('', np.nan).fillna(0).astype(int)\n",
    "games_df[[f'away_{col}' for col in columns]] = games_df.away_line_scores.str.split(',', expand=True).iloc[:, :4].replace('', np.nan).fillna(0).astype(int)\n",
    "\n",
    "games_df = games_df.drop(['home_line_scores', 'away_line_scores'], axis=1)\n",
    "\n",
    "# Reorder\n",
    "movecols = ['game_id', 'game_date']\n",
    "games_df = games_df[movecols + [col for col in games_df.columns if col not in movecols ]]\n",
    "\n",
    "# Normalize Dates\n",
    "# games_df['game_date'] = games_df.game_date.dt.normalize()\n",
    "\n",
    "# Game Stats\n",
    "dropcols = ['points_scored']\n",
    "\n",
    "dfs = []\n",
    "for file in filepath.rglob('games_stats_alt.csv'):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "games_stats_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "games_stats_df = games_stats_df.drop(dropcols, axis=1)\n",
    "games_stats_df = games_stats_df.rename(columns=dict(school='school_id'))\n",
    "\n",
    "# Advanced Stats\n",
    "dropcols = ['week', 'opponent']\n",
    "\n",
    "dfs = []\n",
    "for file in filepath.rglob('games_advanced_stats.csv'):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "games_adv_stats_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "games_adv_stats_df = games_adv_stats_df.drop(dropcols, axis=1)\n",
    "games_adv_stats_df = games_adv_stats_df.rename(columns=dict(team='school_id', gameId='game_id'))\n",
    "games_adv_stats_df = games_adv_stats_df.fillna(0)\n",
    "\n",
    "# Merge Stats\n",
    "games_stats_df = games_stats_df.merge(games_adv_stats_df, on=['game_id', 'school_id'],validate='one_to_one')\n",
    "\n",
    "# Add Game Date for Rolling Calculations\n",
    "games_stats_df = games_stats_df.merge(games_df[['game_id', 'game_date']], on='game_id')\n",
    "\n",
    "# Reorder\n",
    "movecols = ['game_id', 'school_id', 'home_away', 'game_date', 'season']\n",
    "games_stats_df = games_stats_df[movecols + [col for col in games_stats_df.columns if col not in movecols ]]\n",
    "games_stats_df = games_stats_df.fillna(0)\n",
    "\n",
    "# Need to convert school_id to categorical for featuretools cutofftime\n",
    "games_stats_df['school_id'] = games_stats_df.school_id.astype('category')\n",
    "categorical_map = dict(zip(games_stats_df.school_id.cat.codes, games_stats_df.school_id))\n",
    "\n",
    "# Seperate Stats into Home and Away\n",
    "games_stats_home_df = games_stats_df[games_stats_df['home_away'] == 'home'].drop('home_away', axis=1)\n",
    "# games_stats_home_df.columns = games_stats_home_df.columns.map(lambda x : x +'_home' if x not in ['game_id', 'school_id', 'game_date', 'season'] else x)\n",
    "\n",
    "games_stats_away_df = games_stats_df[games_stats_df['home_away'] == 'away'].drop('home_away', axis=1)\n",
    "# games_stats_away_df.columns = games_stats_away_df.columns.map(lambda x : x +'_away' if x not in ['game_id', 'school_id', 'game_date', 'season'] else x)\n",
    "\n",
    "# Merge games_df points for rolling feature calculation\n",
    "\n",
    "home_cols = ['game_id', 'home_points', 'actual_rolling_spread', 'actual_rolling_overunder', 'home_first_qtr_score',\n",
    "             'home_second_qtr_score', 'home_third_qtr_score', 'home_fourth_qtr_score']\n",
    "\n",
    "away_cols = ['game_id', 'away_points', 'away_first_qtr_score','away_second_qtr_score', \n",
    "             'away_third_qtr_score', 'away_fourth_qtr_score']\n",
    "\n",
    "games_stats_home_df = games_stats_home_df.merge(games_df[home_cols], on='game_id', how='left', validate='one_to_one')\n",
    "\n",
    "games_stats_home_df.rename(columns=dict(\n",
    "    home_points='points', \n",
    "    home_first_qtr_score='first_qtr_score',\n",
    "    home_second_qtr_score='second_qtr_score',\n",
    "    home_third_qtr_score='third_qtr_score',\n",
    "    home_fourth_qtr_score='fourth_qtr_score')\n",
    "    )\n",
    "\n",
    "games_stats_away_df = games_stats_away_df.merge(games_df[away_cols], on='game_id', how='left', validate='one_to_one')\n",
    "\n",
    "games_stats_away_df.rename(columns=dict(\n",
    "    away_points='points', \n",
    "    away_first_qtr_score='first_qtr_score',\n",
    "    away_second_qtr_score='second_qtr_score',\n",
    "    away_third_qtr_score='third_qtr_score',\n",
    "    away_fourth_qtr_score='fourth_qtr_score')\n",
    "    )\n",
    "\n",
    "# Drop Columns not needed in games_df\n",
    "drop_cols = ['home_points', 'home_first_qtr_score', 'home_second_qtr_score', 'home_third_qtr_score', 'home_fourth_qtr_score',  \n",
    "             'away_points', 'away_first_qtr_score','away_second_qtr_score', 'away_third_qtr_score', 'away_fourth_qtr_score',\n",
    "             'actual_rolling_spread', 'actual_rolling_overunder']\n",
    "\n",
    "games_df = games_df.drop(drop_cols, axis=1)\n",
    "\n",
    "games_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   season         school_id           season_team_id  recruiting_rank  \\\n",
       "0    2015    South Carolina    2015 - South Carolina               20   \n",
       "1    2015               UCF               2015 - UCF               71   \n",
       "2    2015  Central Michigan  2015 - Central Michigan               97   \n",
       "3    2015       Wake Forest       2015 - Wake Forest               51   \n",
       "4    2015        Ball State        2015 - Ball State              105   \n",
       "\n",
       "   recruiting_points  talent_score  \n",
       "0             230.49        725.72  \n",
       "1             160.78        484.54  \n",
       "2             123.63        376.81  \n",
       "3             176.85        497.48  \n",
       "4             119.70        349.94  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>season</th>\n      <th>school_id</th>\n      <th>season_team_id</th>\n      <th>recruiting_rank</th>\n      <th>recruiting_points</th>\n      <th>talent_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015</td>\n      <td>South Carolina</td>\n      <td>2015 - South Carolina</td>\n      <td>20</td>\n      <td>230.49</td>\n      <td>725.72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015</td>\n      <td>UCF</td>\n      <td>2015 - UCF</td>\n      <td>71</td>\n      <td>160.78</td>\n      <td>484.54</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015</td>\n      <td>Central Michigan</td>\n      <td>2015 - Central Michigan</td>\n      <td>97</td>\n      <td>123.63</td>\n      <td>376.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015</td>\n      <td>Wake Forest</td>\n      <td>2015 - Wake Forest</td>\n      <td>51</td>\n      <td>176.85</td>\n      <td>497.48</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015</td>\n      <td>Ball State</td>\n      <td>2015 - Ball State</td>\n      <td>105</td>\n      <td>119.70</td>\n      <td>349.94</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Teams and Season (Inlcudes Talent and Recruiting Teams)\n",
    "\n",
    "# Recruiting Teams\n",
    "dropcols = ['year', 'team']\n",
    "\n",
    "dfs = []\n",
    "for file in filepath.rglob('recruiting_teams.csv'):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "recruiting_team_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "recruiting_team_df['season_team_id'] = recruiting_team_df['year'].astype(str) + ' - ' + recruiting_team_df['team']\n",
    "recruiting_team_df = recruiting_team_df.drop(dropcols, axis=1)\n",
    "recruiting_team_df = recruiting_team_df.rename(columns=dict(rank='recruiting_rank', points='recruiting_points'))\n",
    "\n",
    "# Talent\n",
    "dfs = []\n",
    "for file in filepath.rglob('talent.csv'):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "talent_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "talent_df = talent_df.rename(columns=dict(talent='talent_score'))\n",
    "talent_df['season_team_id'] = talent_df['year'].astype(str) + ' - ' + talent_df['school']\n",
    "talent_df = talent_df.drop(['year', 'school'], axis=1)\n",
    "talent_df = talent_df.drop_duplicates(subset=['season_team_id'])\n",
    "\n",
    "# Teams and Season\n",
    "team_season_df = games_df[['season', 'home_team', 'away_team']]\n",
    "\n",
    "team_season_df = pd.concat([\n",
    "    team_season_df[['season', 'home_team']].rename(columns=dict(home_team='school_id')), \n",
    "    team_season_df[['season', 'away_team']].rename(columns=dict(away_team='school_id'))\n",
    "    ]).drop_duplicates()\n",
    "\n",
    "team_season_df['season_team_id'] = team_season_df['season'].astype(str) + ' - ' + team_season_df['school_id']\n",
    "\n",
    "# Merge Tables\n",
    "team_season_df = team_season_df.merge(recruiting_team_df, on='season_team_id', validate='one_to_one')\n",
    "team_season_df.head()\n",
    "team_season_df = team_season_df.merge(talent_df, on='season_team_id', validate='one_to_one')\n",
    "\n",
    "# Missing Values\n",
    "team_season_df[['recruiting_rank', 'recruiting_points', 'talent_score']] = team_season_df[['recruiting_rank', 'recruiting_points', 'talent_score']].fillna(team_season_df[['recruiting_rank', 'recruiting_points', 'talent_score']].mean())\n",
    "\n",
    "team_season_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   roster_id    season_team_id  roster_weight  roster_height  roster_year  \\\n",
       "0          0  2015 - Air Force     225.000000           74.0     3.321429   \n",
       "1          1  2015 - Air Force     188.964706           72.0     3.380282   \n",
       "2          2  2015 - Air Force     229.230769           76.0     3.600000   \n",
       "3          3  2015 - Air Force     188.964706           73.0     3.380282   \n",
       "4          4  2015 - Air Force     194.285714           70.0     4.000000   \n",
       "\n",
       "  roster_position roster_home_state  \n",
       "0              LB                IL  \n",
       "1              DB                GA  \n",
       "2              TE                KS  \n",
       "3              DB                GA  \n",
       "4               ?                TX  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roster_id</th>\n      <th>season_team_id</th>\n      <th>roster_weight</th>\n      <th>roster_height</th>\n      <th>roster_year</th>\n      <th>roster_position</th>\n      <th>roster_home_state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2015 - Air Force</td>\n      <td>225.000000</td>\n      <td>74.0</td>\n      <td>3.321429</td>\n      <td>LB</td>\n      <td>IL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2015 - Air Force</td>\n      <td>188.964706</td>\n      <td>72.0</td>\n      <td>3.380282</td>\n      <td>DB</td>\n      <td>GA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2015 - Air Force</td>\n      <td>229.230769</td>\n      <td>76.0</td>\n      <td>3.600000</td>\n      <td>TE</td>\n      <td>KS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2015 - Air Force</td>\n      <td>188.964706</td>\n      <td>73.0</td>\n      <td>3.380282</td>\n      <td>DB</td>\n      <td>GA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2015 - Air Force</td>\n      <td>194.285714</td>\n      <td>70.0</td>\n      <td>4.000000</td>\n      <td>?</td>\n      <td>TX</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Roster\n",
    "usecols = ['id', 'weight', 'height', 'year', 'position', 'home_state', 'team', 'season']\n",
    "\n",
    "dfs = []\n",
    "for file in filepath.rglob('roster.csv'):\n",
    "\n",
    "    df = pd.read_csv(file, usecols=usecols)\n",
    "    dfs.append(df)\n",
    "\n",
    "roster_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# Missing Values\n",
    "roster_df[['weight', 'height', 'year']] = roster_df[['weight', 'height', 'year']].fillna(roster_df.groupby(['team', 'position', 'year'])[['weight', 'height', 'year']].transform('mean'))\n",
    "roster_df[['weight', 'height', 'year']] = roster_df[['weight', 'height', 'year']].fillna(roster_df.groupby(['team', 'position'])[['weight', 'height', 'year']].transform('mean'))\n",
    "roster_df[['weight', 'height', 'year']] = roster_df[['weight', 'height', 'year']].fillna(roster_df.groupby(['position'])[['weight', 'height', 'year']].transform('mean'))\n",
    "roster_df[['weight', 'height', 'year']] = roster_df[['weight', 'height', 'year']].fillna(roster_df.groupby(['team'])[['weight', 'height', 'year']].transform('mean'))\n",
    "roster_df[['weight', 'height', 'year']] = roster_df[['weight', 'height', 'year']].fillna(roster_df[['weight', 'height', 'year']].mean())\n",
    "\n",
    "roster_df = roster_df.rename(columns=dict(id='roster_id', \n",
    "                                          weight='roster_weight', \n",
    "                                          height='roster_height', \n",
    "                                          year='roster_year', \n",
    "                                          position='roster_position', \n",
    "                                          home_state='roster_home_state')\n",
    "                                          )\n",
    "\n",
    "roster_df['roster_id'] = roster_df.index\n",
    "roster_df['season_team_id'] = roster_df['season'].astype(str) + ' - ' + roster_df['team']\n",
    "roster_df = roster_df.drop(['season', 'team'], axis=1)\n",
    "\n",
    "# Reorder\n",
    "movecols = ['roster_id', 'season_team_id']\n",
    "roster_df = roster_df[movecols + [col for col in roster_df.columns if col not in movecols ]]\n",
    "\n",
    "\n",
    "roster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   recruiting_id    season_team_id   positionGroup  averageRating  \\\n",
       "0              0  2015 - Air Force  Defensive Back       0.764333   \n",
       "1              1  2015 - Air Force  Defensive Line       0.771833   \n",
       "2              2  2015 - Air Force      Linebacker       0.733900   \n",
       "3              3  2015 - Air Force  Offensive Line       0.771333   \n",
       "4              4  2015 - Air Force     Quarterback       0.792900   \n",
       "\n",
       "   totalRating  commits  averageStars  \n",
       "0       2.2930        3      2.000000  \n",
       "1       2.3155        3      2.000000  \n",
       "2       1.4678        2      2.000000  \n",
       "3       2.3140        3      2.000000  \n",
       "4       2.3787        3      2.333333  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recruiting_id</th>\n      <th>season_team_id</th>\n      <th>positionGroup</th>\n      <th>averageRating</th>\n      <th>totalRating</th>\n      <th>commits</th>\n      <th>averageStars</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2015 - Air Force</td>\n      <td>Defensive Back</td>\n      <td>0.764333</td>\n      <td>2.2930</td>\n      <td>3</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2015 - Air Force</td>\n      <td>Defensive Line</td>\n      <td>0.771833</td>\n      <td>2.3155</td>\n      <td>3</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2015 - Air Force</td>\n      <td>Linebacker</td>\n      <td>0.733900</td>\n      <td>1.4678</td>\n      <td>2</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2015 - Air Force</td>\n      <td>Offensive Line</td>\n      <td>0.771333</td>\n      <td>2.3140</td>\n      <td>3</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2015 - Air Force</td>\n      <td>Quarterback</td>\n      <td>0.792900</td>\n      <td>2.3787</td>\n      <td>3</td>\n      <td>2.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Recruiting Player\n",
    "dfs = []\n",
    "for file in filepath.rglob('recruiting_position.csv'):\n",
    "\n",
    "    df = pd.read_csv(file)#, usecols=usecols)\n",
    "    dfs.append(df)\n",
    "\n",
    "recruiting_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "recruiting_df = recruiting_df.drop('conference', axis=1)\n",
    "recruiting_df['season_team_id'] = recruiting_df['season'].astype(str) + ' - ' + recruiting_df['team']\n",
    "recruiting_df = recruiting_df.drop(['season', 'team'], axis=1)\n",
    "recruiting_df['recruiting_id'] = recruiting_df.index\n",
    "\n",
    "# Reorder\n",
    "movecols = ['recruiting_id', 'season_team_id']\n",
    "recruiting_df = recruiting_df[movecols + [col for col in recruiting_df.columns if col not in movecols ]]\n",
    "\n",
    "\n",
    "recruiting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     game_id  season  week  actual_spread  actual_overunder  \\\n",
       "0  400603840    2015     1           -4.0              30.0   \n",
       "1  400763593    2015     1            1.0              29.0   \n",
       "2  400763399    2015     1           11.0              37.0   \n",
       "3  400603839    2015     1            2.0              26.0   \n",
       "4  400756883    2015     1           -7.0              41.0   \n",
       "\n",
       "   sportsbook_spread  sportsbook_overunder  is_home_covered  is_over  \\\n",
       "0               -3.5                   NaN                1        0   \n",
       "1              -17.0                   NaN                0        0   \n",
       "2               20.5                   NaN                1        0   \n",
       "3              -17.5                   NaN                0        0   \n",
       "4               -3.0                   NaN                1        0   \n",
       "\n",
       "   is_home_winner  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_id</th>\n      <th>season</th>\n      <th>week</th>\n      <th>actual_spread</th>\n      <th>actual_overunder</th>\n      <th>sportsbook_spread</th>\n      <th>sportsbook_overunder</th>\n      <th>is_home_covered</th>\n      <th>is_over</th>\n      <th>is_home_winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>400603840</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>-4.0</td>\n      <td>30.0</td>\n      <td>-3.5</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>400763593</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>-17.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>400763399</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>37.0</td>\n      <td>20.5</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>400603839</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>26.0</td>\n      <td>-17.5</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>400756883</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>-7.0</td>\n      <td>41.0</td>\n      <td>-3.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Target\n",
    "usecols = ['id', 'season', 'week', 'home_points', 'away_points']\n",
    "\n",
    "dfs = []\n",
    "for file in filepath.rglob('games.csv'):\n",
    "\n",
    "    df = pd.read_csv(file, usecols=usecols)\n",
    "    dfs.append(df)\n",
    "\n",
    "target_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "target_df['actual_spread'] = target_df.away_points - target_df.home_points \n",
    "target_df['actual_overunder'] = target_df.home_points + target_df.away_points \n",
    "target_df = target_df.drop(['home_points', 'away_points'], axis=1)\n",
    "target_df = target_df.rename(columns=dict(id='game_id'))\n",
    "\n",
    "usecols = ['id', 'provider', 'spread', 'overUnder']\n",
    "\n",
    "dfs = []\n",
    "for file in filepath.rglob('lines.csv'):\n",
    "\n",
    "    df = pd.read_csv(file, usecols=usecols)\n",
    "    dfs.append(df[df.provider=='consensus'])\n",
    "\n",
    "lines_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "lines_df = lines_df.drop('provider', axis=1)\n",
    "lines_df = lines_df.rename(columns=dict(id='game_id', spread='sportsbook_spread', overUnder='sportsbook_overunder'))\n",
    "\n",
    "# Merge Actual and Lines\n",
    "target_df = target_df.merge(lines_df, on='game_id', how='inner', validate='one_to_one')\n",
    "\n",
    "# Create Targets for Classifier\n",
    "target_df['is_home_covered'] = np.where(target_df.actual_spread.lt(target_df.sportsbook_spread), 1, 0)\n",
    "target_df['is_over'] = np.where(target_df.actual_overunder.gt(target_df.sportsbook_overunder), 1, 0)\n",
    "target_df['is_home_winner'] = np.where(target_df.actual_spread.lt(0), 1, 0)\n",
    "\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Built 472 features\n",
      "Elapsed: 00:01 | Progress: 100%|██████████\n",
      "Built 472 features\n",
      "Elapsed: 00:01 | Progress: 100%|██████████\n"
     ]
    }
   ],
   "source": [
    "# ETS\n",
    "home_es = ft.EntitySet(id='home')\n",
    "away_es = ft.EntitySet(id='away')\n",
    "\n",
    "# Add Teams|Seasons Entity\n",
    "home_es = home_es.entity_from_dataframe(\n",
    "            entity_id='team_season',\n",
    "            dataframe=team_season_df,\n",
    "            index='season_team_id',\n",
    "            variable_types={'school_id': ft.variable_types.Id})\n",
    "away_es = away_es.entity_from_dataframe(\n",
    "            entity_id='team_season',\n",
    "            dataframe=team_season_df,    \n",
    "            index='season_team_id',\n",
    "            variable_types={'school_id': ft.variable_types.Id})\n",
    "\n",
    "# Add Roster Entity\n",
    "home_es = home_es.entity_from_dataframe(\n",
    "            entity_id='roster',\n",
    "            dataframe=roster_df,\n",
    "            index='roster_id',\n",
    "            variable_types={\n",
    "                'roster_position': ft.variable_types.Categorical,\n",
    "                'roster_home_state': ft.variable_types.Categorical})\n",
    "away_es = away_es.entity_from_dataframe(\n",
    "            entity_id='roster',\n",
    "            dataframe=roster_df,    \n",
    "            index='roster_id',\n",
    "            variable_types={\n",
    "                'roster_position': ft.variable_types.Categorical,\n",
    "                'roster_home_state': ft.variable_types.Categorical,\n",
    "                'season_team_id': ft.variable_types.Id})\n",
    "\n",
    "# Add Recruiting Entity\n",
    "home_es = home_es.entity_from_dataframe(\n",
    "            entity_id='recruiting',\n",
    "            dataframe=recruiting_df,\n",
    "            index='recruiting_id',\n",
    "            variable_types={'positionGroup': ft.variable_types.Categorical})\n",
    "away_es = away_es.entity_from_dataframe(\n",
    "            entity_id='recruiting',\n",
    "            dataframe=recruiting_df,    \n",
    "            index='recruiting_id',\n",
    "            variable_types={'positionGroup': ft.variable_types.Categorical})\n",
    "\n",
    "# Add Games Entity\n",
    "# Seperate Games into Home and Away Games\n",
    "home_cols = ['game_id', 'season', 'home_team']\n",
    "aways_cols = ['game_id', 'season', 'away_team']\n",
    "\n",
    "home_games_df = games_df[home_cols]\n",
    "away_games_df = games_df[aways_cols]\n",
    "\n",
    "home_games_df['season_team_id'] = home_games_df['season'].astype(str) + ' - ' + home_games_df['home_team']\n",
    "away_games_df['season_team_id'] = away_games_df['season'].astype(str) + ' - ' + away_games_df['away_team']\n",
    "\n",
    "home_games_df = home_games_df.rename(columns=dict(home_team='team'))\n",
    "away_games_df = away_games_df.rename(columns=dict(away_team='team'))\n",
    "\n",
    "home_es = home_es.entity_from_dataframe(\n",
    "            entity_id='games',\n",
    "            dataframe=home_games_df,\n",
    "            index='game_id')\n",
    "away_es = away_es.entity_from_dataframe(\n",
    "            entity_id='games',\n",
    "            dataframe=away_games_df,    \n",
    "            index='game_id')\n",
    "\n",
    "# Create Relationships\n",
    "relationships = [\n",
    "  # parent_entity   parent_variable  child_entity  child_variable\n",
    "  ('team_season',  'season_team_id', 'recruiting', 'season_team_id'),\n",
    "  ('team_season',  'season_team_id', 'roster',     'season_team_id'),\n",
    "  ('team_season',  'season_team_id', 'games',      'season_team_id')\n",
    "]\n",
    "\n",
    "# Apply the relationships\n",
    "for es in [home_es, away_es]:\n",
    "    for pe, pv, ce, cv in relationships:\n",
    "        es = es.add_relationship(ft.Relationship(es[pe][pv], es[ce][cv]))\n",
    "\n",
    "# Add interesting valuees\n",
    "home_es['recruiting']['positionGroup'].interesting_values = recruiting_df.positionGroup.unique()\n",
    "away_es['recruiting']['positionGroup'].interesting_values = recruiting_df.positionGroup.unique()\n",
    "\n",
    "home_es['roster']['roster_position'].interesting_values = roster_df.roster_position.unique()\n",
    "away_es['roster']['roster_position'].interesting_values = roster_df.roster_position.unique()\n",
    "\n",
    "features = [\"mean\", \"max\", \"min\", \"sum\"]\n",
    "\n",
    "# Home Features\n",
    "home_teams_season_feat, home_dfs_defs = ft.dfs(entityset=home_es,\n",
    "                            target_entity='games',\n",
    "                            agg_primitives=features,\n",
    "                            where_primitives=features,\n",
    "                            verbose = True)\n",
    "\n",
    "# Away Features\n",
    "away_teams_season_feat, away_dfs_defs = ft.dfs(entityset=away_es,\n",
    "                            target_entity='games',\n",
    "                            agg_primitives=features,\n",
    "                            where_primitives=features,\n",
    "                            verbose = True)\n",
    "\n",
    "# Remove low information features\n",
    "home_teams_season_feat = ft.selection.remove_low_information_features(home_teams_season_feat)\n",
    "away_teams_season_feat = ft.selection.remove_low_information_features(away_teams_season_feat)\n",
    "\n",
    "# Align  Features\n",
    "home_teams_season_feat, away_teams_season_feat = home_teams_season_feat.align(away_teams_season_feat, join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Built 429 features\n",
      "Elapsed: 11:05 | Progress: 100%|██████████\n",
      "Built 421 features\n",
      "Elapsed: 10:30 | Progress: 100%|██████████\n"
     ]
    }
   ],
   "source": [
    "# Rolling ETS\n",
    "\n",
    "# Home & Away\n",
    "# Remove timezone https://github.com/FeatureLabs/featuretools/issues/498\n",
    "games_stats_home_df['game_date'] = games_stats_home_df['game_date'].dt.tz_convert(None)\n",
    "games_stats_away_df['game_date'] = games_stats_away_df['game_date'].dt.tz_convert(None)\n",
    "\n",
    "# Index must be numeric for cutofftimes\n",
    "games_stats_home_df['school_id'] = games_stats_home_df.school_id.cat.codes\n",
    "games_stats_away_df['school_id'] = games_stats_away_df.school_id.cat.codes\n",
    "\n",
    "\n",
    "# Create Entity Sets\n",
    "rolling_home_es = ft.EntitySet(id='rolling_home')\n",
    "rolling_away_es = ft.EntitySet(id='rolling_away')\n",
    "\n",
    "# Home ES\n",
    "rolling_home_es = rolling_home_es.entity_from_dataframe(\n",
    "                            entity_id=\"game_stats\",\n",
    "                            dataframe=games_stats_home_df,\n",
    "                            index=\"game_id\",\n",
    "                            time_index=\"game_date\")\n",
    "\n",
    "rolling_home_es = rolling_home_es.entity_from_dataframe(\n",
    "                            entity_id=\"schools\",\n",
    "                            dataframe=pd.DataFrame(games_stats_home_df['school_id'].drop_duplicates()),\n",
    "                            index=\"school_id\")\n",
    "\n",
    "# Away ES\n",
    "rolling_away_es = rolling_away_es.entity_from_dataframe(\n",
    "                            entity_id=\"game_stats\",\n",
    "                            dataframe=games_stats_away_df,\n",
    "                            index=\"game_id\",\n",
    "                            time_index=\"game_date\")\n",
    "\n",
    "rolling_away_es = rolling_away_es.entity_from_dataframe(\n",
    "                            entity_id=\"schools\",\n",
    "                            dataframe=pd.DataFrame(games_stats_away_df['school_id'].drop_duplicates()),\n",
    "                            index=\"school_id\")\n",
    "\n",
    "# Create Relationships\n",
    "relationships = [\n",
    "  # parent_entity   parent_variable  child_entity  child_variable\n",
    "  ('schools',  'school_id', 'game_stats', 'school_id'),\n",
    "]\n",
    "\n",
    "# Apply the relationships\n",
    "for es in [rolling_home_es, rolling_away_es]:\n",
    "    for pe, pv, ce, cv in relationships:\n",
    "        es = es.add_relationship(ft.Relationship(es[pe][pv], es[ce][cv]))\n",
    "\n",
    "cutoff_home_times = pd.DataFrame()\n",
    "cutoff_home_times[['game_id', 'game_date']] = games_stats_home_df[['game_id', 'game_date']]\n",
    "\n",
    "cutoff_away_times = pd.DataFrame()\n",
    "cutoff_away_times[['game_id', 'game_date']] = games_stats_away_df[['game_id', 'game_date']]\n",
    "\n",
    "features = [\"mean\", \"max\", \"min\"]\n",
    "\n",
    "# Home Features\n",
    "home_rolling_feat, rolling_home_dfs_defs = ft.dfs(\n",
    "                            entityset=rolling_home_es,\n",
    "                            target_entity='game_stats',\n",
    "                            agg_primitives=features,\n",
    "                            cutoff_time=cutoff_home_times,\n",
    "                            training_window='2 months',\n",
    "                            cutoff_time_in_index=True,\n",
    "                            verbose = True)\n",
    "\n",
    "# Away Features\n",
    "away_rolling_feat, rolling_away_dfs_defs = ft.dfs(\n",
    "                            entityset=rolling_away_es,\n",
    "                            target_entity='game_stats',\n",
    "                            agg_primitives=features,\n",
    "                            cutoff_time=cutoff_away_times,\n",
    "                            training_window='2 months',\n",
    "                            cutoff_time_in_index=True,\n",
    "                            verbose = True)\n",
    "\n",
    "\n",
    "# Remove low information features\n",
    "home_rolling_feat = ft.selection.remove_low_information_features(home_rolling_feat)\n",
    "away_rolling_feat = ft.selection.remove_low_information_features(away_rolling_feat)\n",
    "\n",
    "# Align  Features\n",
    "home_rolling_feat, away_rolling_feat = home_rolling_feat.align(away_rolling_feat, join='inner', axis=1)\n",
    "\n",
    "home_rolling_feat.to_hdf('home_rolling_feat.h5', key='home_rolling_feat', mode='w')\n",
    "away_rolling_feat.to_hdf('away_rolling_feat.h5', key='away_rolling_feat', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TO SKIP ABOVE\n",
    "home_rolling_feat = pd.read_hdf('home_rolling_feat.h5')\n",
    "away_rolling_feat = pd.read_hdf('away_rolling_feat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Up Feature Tools Dataframes\n",
    "\n",
    "#################### Team_Season ##########################\n",
    "home_teams_season_feat = home_teams_season_feat.reset_index()\n",
    "home_teams_season_feat = home_teams_season_feat.drop(['season_team_id', 'team_season.season', 'team_season.school_id'], axis=1)\n",
    "# home_teams_season_feat.columns = home_teams_season_feat.columns.map(lambda x : x +'_home' if x not in ['game_id', 'season', 'team'] else x)\n",
    "\n",
    "away_teams_season_feat = away_teams_season_feat.reset_index()\n",
    "away_teams_season_feat = away_teams_season_feat.drop(['season_team_id', 'team_season.season', 'team_season.school_id'], axis=1)\n",
    "# away_teams_season_feat.columns = away_teams_season_feat.columns.map(lambda x : x +'_away' if x not in ['game_id', 'season', 'team'] else x)\n",
    "\n",
    "###################### Rolling ############################\n",
    "drop_cols = ['DAY(game_date)', 'MONTH(game_date)', 'WEEKDAY(game_date)', 'YEAR(game_date)', 'time']\n",
    "\n",
    "home_rolling_feat = home_rolling_feat.reset_index().drop(drop_cols, axis=1)\n",
    "home_rolling_feat['school_id'] = home_rolling_feat.school_id.map(categorical_map)\n",
    "\n",
    "away_rolling_feat = away_rolling_feat.reset_index().drop(drop_cols, axis=1)\n",
    "away_rolling_feat['school_id'] = away_rolling_feat.school_id.map(categorical_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep for Model\n",
    "\n",
    "###################### Games ############################\n",
    "# Fill Missing Values\n",
    "games_df['capacity_perc'] = np.where(np.isinf(games_df['capacity_perc']), np.nan, games_df['capacity_perc'])\n",
    "games_df[['attendance' , 'capacity_perc', 'elevation']] = games_df[['attendance' , 'capacity_perc', 'elevation']].fillna(games_df.groupby('venue_id')[['attendance' , 'capacity_perc', 'elevation']].transform('mean'))\n",
    "games_df[['attendance' , 'capacity_perc', 'elevation']] = games_df[['attendance' , 'capacity_perc', 'elevation']].fillna(games_df[['attendance' , 'capacity_perc', 'elevation']].mean())\n",
    "games_df[['home_conference', 'away_conference']] = games_df[['home_conference', 'away_conference']].fillna('missing')\n",
    "\n",
    "# Shift Venue Attendance Forward\n",
    "games_df[['attendance', 'capacity_perc']] = games_df.groupby(['venue_id'])[['attendance', 'capacity_perc']].shift(1)\n",
    "\n",
    "#################### Team_Season ##########################\n",
    "home_cols = home_teams_season_feat.iloc[:,3:].columns\n",
    "away_cols = away_teams_season_feat.iloc[:,3:].columns\n",
    "\n",
    "# Home Fill Missing\n",
    "home_teams_season_feat[home_cols] = home_teams_season_feat[home_cols].fillna(home_teams_season_feat.groupby(['season', 'team'])[home_cols].transform('mean'))\n",
    "home_teams_season_feat[home_cols] = home_teams_season_feat[home_cols].fillna(home_teams_season_feat.groupby(['team'])[home_cols].transform('mean'))\n",
    "home_teams_season_feat[home_cols] = home_teams_season_feat[home_cols].fillna(home_teams_season_feat[home_cols].mean())\n",
    "1\n",
    "# Away Fill Missing\n",
    "away_teams_season_feat[away_cols] = away_teams_season_feat[away_cols].fillna(away_teams_season_feat.groupby(['season', 'team'])[away_cols].transform('mean'))\n",
    "away_teams_season_feat[away_cols] = away_teams_season_feat[away_cols].fillna(away_teams_season_feat.groupby(['team'])[away_cols].transform('mean'))\n",
    "away_teams_season_feat[away_cols] = away_teams_season_feat[away_cols].fillna(away_teams_season_feat[away_cols].mean())\n",
    "\n",
    "###################### Rolling ############################\n",
    "home_cols = home_rolling_feat.iloc[:,3:].columns\n",
    "away_cols = away_rolling_feat.iloc[:,3:].columns\n",
    "\n",
    "# Home Fill Missing\n",
    "home_rolling_feat[home_cols] = home_rolling_feat[home_cols].fillna(home_rolling_feat.groupby(['season', 'school_id'])[home_cols].transform('mean'))\n",
    "home_rolling_feat[home_cols] = home_rolling_feat[home_cols].fillna(home_rolling_feat.groupby(['school_id'])[home_cols].transform('mean'))\n",
    "home_rolling_feat[home_cols] = home_rolling_feat[home_cols].fillna(home_rolling_feat[home_cols].mean())\n",
    "\n",
    "# Shift Game Stats Forward\n",
    "home_rolling_feat[home_cols] = home_rolling_feat.groupby(['school_id'])[home_cols].shift(1)\n",
    "\n",
    "# Away Fill Missing\n",
    "away_rolling_feat[away_cols] = away_rolling_feat[away_cols].fillna(away_rolling_feat.groupby(['season', 'school_id'])[away_cols].transform('mean'))\n",
    "away_rolling_feat[away_cols] = away_rolling_feat[away_cols].fillna(away_rolling_feat.groupby(['school_id'])[away_cols].transform('mean'))\n",
    "away_rolling_feat[away_cols] = away_rolling_feat[away_cols].fillna(away_rolling_feat[away_cols].mean())\n",
    "\n",
    "# Shift Game Stats Forward\n",
    "away_rolling_feat[away_cols] = away_rolling_feat.groupby(['school_id'])[away_cols].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Home and Away Features Together\n",
    "teams_season_feat_interaction = (home_teams_season_feat.set_index('game_id').iloc[:,2:] - \n",
    "                                away_teams_season_feat.set_index('game_id').iloc[:,2:])\n",
    "\n",
    "rolling_feat_interaction = (home_rolling_feat.set_index('game_id').iloc[:,2:] - \n",
    "                            away_rolling_feat.set_index('game_id').iloc[:,2:])\n",
    "\n",
    "teams_season_feat_interaction = teams_season_feat_interaction.add_suffix('_interaction')\n",
    "rolling_feat_interaction = rolling_feat_interaction.add_suffix('_interaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Games and Stats\n",
    "features_df = games_df.merge(\n",
    "                home_teams_season_feat.drop(['season', 'team'], axis=1), how='left', validate='one_to_one', on='game_id').merge(\n",
    "                away_teams_season_feat.drop(['season', 'team'], axis=1), how='left', validate='one_to_one', on='game_id').merge(                      \n",
    "                home_rolling_feat.drop(['school_id', 'season'], axis=1), how='left', validate='one_to_one', on='game_id').merge( \n",
    "                away_rolling_feat.drop(['school_id', 'season'], axis=1), how='left', validate='one_to_one', on='game_id').merge(\n",
    "                teams_season_feat_interaction, how='left', validate='one_to_one', left_on='game_id', right_index=True).merge(    \n",
    "                rolling_feat_interaction, how='left', validate='one_to_one', left_on='game_id', right_index=True)\n",
    "\n",
    "features_df.columns = features_df.columns.str.replace('_x', '_home')\n",
    "features_df.columns = features_df.columns.str.replace('_y', '_away')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove Games will Null Features & Date\n",
    "features_df = features_df.dropna()\n",
    "features_df = features_df.drop('game_date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set game_id as index for Alignment\n",
    "features_df = features_df.set_index('game_id')\n",
    "target_df = target_df.set_index('game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV \n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "ct = make_column_transformer(\n",
    "        (OneHotEncoder(handle_unknown='ignore'), ['season_type', 'home_team', 'away_team', 'home_conference', 'away_conference']), \n",
    "        remainder='passthrough'\n",
    "        )\n",
    "\n",
    "# Align Target with Features\n",
    "features, target = features_df.align(target_df, join='inner', axis=0)\n",
    "\n",
    "features_train, features_test = features[features.season < 2019], features[features.season >= 2019]\n",
    "target_train, target_test =  target[target.season < 2019], target[target.season >= 2019]\n",
    "\n",
    "# Spread & Over Under Model Fitted with GridSearch\n",
    "spread_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
    "                importance_type='gain', interaction_constraints='',\n",
    "                learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "                min_child_weight=5, missing=np.nan, monotone_constraints='()',\n",
    "                n_estimators=5000, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.9,\n",
    "                tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "spread_pipe = make_pipeline(ct, spread_model)\n",
    "spread_pipe.fit(features_train, target_train.actual_spread)\n",
    "\n",
    "spread_pred = pd.DataFrame({'Spread Prediction': spread_pipe.predict(features_test)}, index=features_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18.174853302765275"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(target_test.actual_spread, spread_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align Target with Features\n",
    "overunder_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
    "                importance_type='gain', interaction_constraints='',\n",
    "                learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "                min_child_weight=5, missing=np.nan, monotone_constraints='()',\n",
    "                n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.9,\n",
    "                tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "overunder_pipe = make_pipeline(ct, overunder_model)\n",
    "overunder_pipe.fit(features_train, target_train.actual_overunder)\n",
    "\n",
    "overunder_pred = pd.DataFrame({'OverUnder Prediction': overunder_pipe.predict(features_test)}, index=features_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
    "                importance_type='gain', interaction_constraints='',\n",
    "                learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "                min_child_weight=5, missing=np.nan, monotone_constraints='()',\n",
    "                n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.7,\n",
    "                tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "# Calibrate Probabilities\n",
    "class_model = CalibratedClassifierCV(\n",
    "                        base_estimator=class_model,\n",
    "                        method='isotonic'\n",
    "                        )\n",
    "\n",
    "class_pipe = make_pipeline(ct, class_model)\n",
    "class_pipe.fit(features_train, target_train.is_home_winner)\n",
    "\n",
    "class_pred = pd.DataFrame({'is Home Winner Prediction': class_pipe.predict(features_test)}, index=features_test.index)\n",
    "\n",
    "class_pred_prob = pd.DataFrame({'Home Win Probability': class_pipe.predict_proba(features_test)[:,1], 'Away Win Probability': class_pipe.predict_proba(features_test)[:,0]}, index=features_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Spread Prediction  OverUnder Prediction  is Hoem Winner Prediction  \\\n",
       "game_id                                                                         \n",
       "401110723         -10.772289             53.842068                          1   \n",
       "401114164           3.001189             61.447735                          0   \n",
       "401117855         -20.416349             63.174084                          1   \n",
       "401117854          -7.760563             59.069340                          1   \n",
       "401119254         -15.366954             61.977047                          1   \n",
       "\n",
       "           Home Win Probability  Away Win Probability  \n",
       "game_id                                                \n",
       "401110723              0.879357              0.120643  \n",
       "401114164              0.364316              0.635684  \n",
       "401117855              0.783928              0.216072  \n",
       "401117854              0.690394              0.309606  \n",
       "401119254              0.786283              0.213717  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Spread Prediction</th>\n      <th>OverUnder Prediction</th>\n      <th>is Hoem Winner Prediction</th>\n      <th>Home Win Probability</th>\n      <th>Away Win Probability</th>\n    </tr>\n    <tr>\n      <th>game_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>401110723</th>\n      <td>-10.772289</td>\n      <td>53.842068</td>\n      <td>1</td>\n      <td>0.879357</td>\n      <td>0.120643</td>\n    </tr>\n    <tr>\n      <th>401114164</th>\n      <td>3.001189</td>\n      <td>61.447735</td>\n      <td>0</td>\n      <td>0.364316</td>\n      <td>0.635684</td>\n    </tr>\n    <tr>\n      <th>401117855</th>\n      <td>-20.416349</td>\n      <td>63.174084</td>\n      <td>1</td>\n      <td>0.783928</td>\n      <td>0.216072</td>\n    </tr>\n    <tr>\n      <th>401117854</th>\n      <td>-7.760563</td>\n      <td>59.069340</td>\n      <td>1</td>\n      <td>0.690394</td>\n      <td>0.309606</td>\n    </tr>\n    <tr>\n      <th>401119254</th>\n      <td>-15.366954</td>\n      <td>61.977047</td>\n      <td>1</td>\n      <td>0.786283</td>\n      <td>0.213717</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "df = pd.concat([spread_pred, overunder_pred, class_pred, class_pred_prob], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join(target_test.drop(['season', 'week'], axis=1)).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7244582043343654"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "pred = model.predict(ct.fit_transform(features_test))\n",
    "pred_prob = model.predict_proba(ct.transform(features_test))\n",
    "pred_prob = np.max(pred_prob, axis=1)\n",
    "accuracy_score(target_test.is_home_winner, pred)\n",
    "\n",
    "# Best: 0.5237603305785123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  win  count\n",
       "bin                         \n",
       "(0.5, 0.55]  0.392157     51\n",
       "(0.55, 0.6]  0.487179     39\n",
       "(0.6, 0.7]   0.530864     81\n",
       "(0.7, 0.8]   0.639344    122\n",
       "(0.8, 0.9]   0.653846    156\n",
       "(0.9, 1.0]   0.846154    520"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>win</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>bin</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(0.5, 0.55]</th>\n      <td>0.392157</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>(0.55, 0.6]</th>\n      <td>0.487179</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>(0.6, 0.7]</th>\n      <td>0.530864</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>(0.7, 0.8]</th>\n      <td>0.639344</td>\n      <td>122</td>\n    </tr>\n    <tr>\n      <th>(0.8, 0.9]</th>\n      <td>0.653846</td>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>(0.9, 1.0]</th>\n      <td>0.846154</td>\n      <td>520</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "final = pd.concat(\n",
    "    [target_test.is_home_winner, \n",
    "     pd.Series(pred, index=target_test.index, name='prediction'), \n",
    "     pd.Series(pred_prob, index=target_test.index, name='probability')\n",
    "    ], axis=1)\n",
    "\n",
    "final['result'] = final.is_home_winner == final.prediction\n",
    "\n",
    "final['bin'] = pd.cut(final.probability, [.50, .55, .60, .70, .80, .90, 1])\n",
    "\n",
    "final.groupby('bin')['result'].agg(win=(lambda x: x.sum() / x.count()), count=( 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-82b4ee2d309d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Feature Importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportant_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspread_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimportant_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\zillion_picks\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m             raise ValueError('Number of features of the input must be equal '\n\u001b[0;32m    582\u001b[0m                              \u001b[1;34m'to or greater than that of the fitted '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "important_features = pd.Series(data=spread_model.feature_importances_, index=features_train.columns).sort_values(ascending=False)\n",
    "important_features.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, ..., 0.0, -2.2, 3.9999999999999996],\n",
       "       [0.0, 1.0, 0.0, ..., -1.0, 0.2999999999999998, 3.0],\n",
       "       [0.0, 1.0, 0.0, ..., -2.0, 0.0, 3.8999999999999995],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 1.0, 1.0999999999999996, 1.1999999999999997],\n",
       "       [1.0, 0.0, 0.0, ..., -1.0, 1.5, -0.5],\n",
       "       [1.0, 0.0, 0.0, ..., 0.0, 2.0, 1.1]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "ct.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search\n",
    "# parameters = { \n",
    "#         'objective':['reg:squarederror'],\n",
    "#         'learning_rate': [0.1], \n",
    "#         'max_depth': [3,5,7],\n",
    "#         'min_child_weight': [1,3,5],\n",
    "#         'subsample': [0.5, 0.7, 0.9],\n",
    "#         'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "#         'n_estimators': [50, 100, 400]\n",
    "#         }\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#         XGBRegressor(),\n",
    "#         parameters,\n",
    "#         scoring='neg_mean_squared_error',\n",
    "#         cv = 7,\n",
    "#         n_jobs=-1,\n",
    "#         verbose=True\n",
    "#         )\n",
    "\n",
    "# class_pipe.named_steps['gridsearchcv'].best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('zillion_picks': conda)",
   "display_name": "Python 3.8.5 64-bit ('zillion_picks': conda)",
   "metadata": {
    "interpreter": {
     "hash": "256fd5123dc8e59516eee9d21b9c90667fe410b4aea7ba3cd63acfd5f8147011"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}